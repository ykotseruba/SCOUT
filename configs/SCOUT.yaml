model_class: SCOUT_task

dataset: DReyeVE # Options: DReyeVE, BDD-A

last_weights: None

best_weights: None

model_params:
  img_size: [224,224] # img size for Video Swin Transformer encoder
  use_task: True # set to False to use only visual information
  task_attributes: ['current_action', 'local_context'] # Options: current_action, local_context, global_context
  # global context: video-level labels for weather, time of day, and 
  #                 location (see dr(eye)ve_design.txt that comes with DReyeVE dataset)
  # local context: distance to intersection (m), priority (right-of-way, yield), and
  #                action at the next intersection (turn right, turn left, drive straight)
  # current action: speed (km/h), acceleration (m/s2), action (turn right/left, lane
  #                 change right/left, drive straight)

  transformer_params:
    add_and_norm: True
    fuse_idx: [1, 2] # encoder block(s) where task labels are fused with visual info  
    num_att_heads: [2, 2, 2] # number of heads for each fusion block

  pretrained_backbone: True
  train_backbone: True
  num_encoder_layers: 4 # 1-4 
  clip_size: 16

train_params:
  no_epochs: 10
  lr: 0.0001
  loss:
    kldiv: True
    kldiv_coeff: 1.0
    cc: False
    cc_coeff: -1.0
    nss: False
    nss_coeff: 1.0
    sim: False
    sim_coeff: -1.0
    l1: False
    l1_coeff: 1.0
  lr_sched: True
  early_stop: True
  optimizer: Adam
  batch_size: 4
  log_interval: 10
  no_workers: 4 # number of workers for dataloader
  weighted_sampler: False # select "hard" samples more frequently during training, may not use all samples
  weighted_loss: False # assigns higher weights to "hard" samples in loss calculation
  weight_type: KLdiv

test_params:
  batch_size: 4
  eval: full # Options: full, quick (10% of the data), null (do not evaluate)
  metrics: [KLdiv, NSS, SIM, CC] 
  save_images: False # save saliency maps